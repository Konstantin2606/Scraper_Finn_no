{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaabf82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from fake_useragent import UserAgent as UA\n",
    "import time\n",
    "import json\n",
    "from selenium.webdriver.common.by import By\n",
    "from seleniumwire import webdriver\n",
    "#from selenium.webdriver.support import expected_conditions as EC\n",
    "#from selenium.webdriver.support.ui import WebDriverWait\n",
    "#from selenium.webdriver import Keys\n",
    "\n",
    "#proxy changes\n",
    "\n",
    "options = {'proxy': {\n",
    "        'http': 'http://Qm5ZLm:tjaEeq@45.146.183.178:8000',\n",
    "        'https': 'http://Qm5ZLm:tjaEeq@45.146.183.178:8000'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47d7ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile proxies.py\n",
    "\n",
    "def proxies():\n",
    "    options = {'proxy': {\n",
    "        'http': 'http://Qm5ZLm:tjaEeq@45.146.183.178:8000',\n",
    "        'https': 'http://Qm5ZLm:tjaEeq@45.146.183.178:8000'}}\n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a4e49f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile connect_site.py\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from fake_useragent import UserAgent as UA\n",
    "\n",
    "#requests and bs4 connect\n",
    "def connect(url, params={}, opt={\"proxy\": {}}):\n",
    "    ua = UA()\n",
    "    header = {\n",
    "        'user-agent': ua.random,\n",
    "        'x-requested-with': 'XMLHttpRequest'}\n",
    "    proxies = opt['proxy']\n",
    "    resp = rq.get(url, headers=header, proxies=proxies, params=param, timeout=1)\n",
    "    resp.encoding = 'utf-8-sig'\n",
    "    soup = bs(resp.text, 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af57468a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting collect.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile collect.py\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "from fake_useragent import UserAgent as UA\n",
    "import time\n",
    "\n",
    "\n",
    "#collecting data def\n",
    "def collect(categ, url, param, options):\n",
    "    \n",
    "    #requests and bs4 connect\n",
    "    def connect(url, params={}, opt={\"proxy\": {}}):\n",
    "        ua = UA()\n",
    "        header = {\n",
    "            'user-agent': ua.random,\n",
    "            'x-requested-with': 'XMLHttpRequest'}\n",
    "        proxies = opt['proxy']\n",
    "        resp = rq.get(url, headers=header, proxies=proxies, params=param, timeout=1)\n",
    "        resp.encoding = 'utf-8-sig'\n",
    "        soup = bs(resp.text, 'lxml')\n",
    "        return soup\n",
    "    \n",
    "    alt = []\n",
    "    try:\n",
    "        while True:\n",
    "            soup = connect(url, params=param, opt=options)\n",
    "            print('connection successful')\n",
    "            for i in soup.find_all('article'):\n",
    "                one = []\n",
    "                one.append(i.find(\"a\").text) #name\n",
    "                one.append(i.find('span', {'class':'text-12 text-gray-500'}).text) #from\n",
    "                one.append(i.find('span', {'class':'text-14 text-gray-500'}).text) #adress\n",
    "                #trying to find square_metre, price\n",
    "                sqm_pr = i.find('div', {'class': 'mt-16 flex justify-between sm:mt-8 sm:block space-x-12 font-bold whitespace-nowrap'})\n",
    "                if not sqm_pr:\n",
    "                    sqm_pr = i.find('div', {'class': 'col-span-2 mt-16 flex justify-between sm:mt-4 sm:block space-x-12 font-bold whitespace-nowrap'})\n",
    "                if sqm_pr: #square_metre, price\n",
    "                    for spr in sqm_pr.find_all('span'): \n",
    "                        one.append(spr.text)\n",
    "                #trying to find price_desc, r_type_amount\n",
    "                desq_type = i.find('div', {'class': 'text-12 text-gray-500 flex flex-col mt-4 sm:block sm:mt-8'})\n",
    "                if not desq_type:\n",
    "                    desq_type = i.find('div', {'class': 'text-12 text-gray-500 flex flex-col mt-4 sm:block'})\n",
    "                if desq_type: #price_desc, r_type_amount\n",
    "                    for am in desq_type.find_all('span'):\n",
    "                        if am.text != ' ∙ ':\n",
    "                            one.append(am.text)\n",
    "                visning = i.find('span', {'class':'inline-block px-8 py-4 text-12 border border-bluegray-300 rounded-full'})\n",
    "                if visning:\n",
    "                    one.append(visning.text) #Visning\n",
    "                one.append(i.find('a', {'class': 'sf-search-ad-link link link--dark hover:no-underline'})['href']) #link\n",
    "                alt.append(one)\n",
    "            try:\n",
    "                link = soup.find('nav', {\"class\": 'pagination u-pb8 u-pt16'}).find_all('a')[-1]['href']\n",
    "                link = link[1:]\n",
    "                link = dict(map(lambda x: x.split('='), link.split('&')))\n",
    "                if link['page'] == param['page']:\n",
    "                    raise Exception('Last link.')\n",
    "                else:\n",
    "                    param = link\n",
    "                time.sleep(5)\n",
    "            except:\n",
    "                print('All is collected!')\n",
    "                break    \n",
    "    except Exception as e:\n",
    "        print(f\"Something wrong: {e}\")\n",
    "    return alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be58f785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c7c45b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection successful\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.finn.no/realestate/homes/search.html'\n",
    "param = 'geoLocationName=Bergen&lat=60.39358&lon=5.32479&radius=3000&sort=PUBLISHED_DESC'\n",
    "options = proxies()\n",
    "\n",
    "soup = connect(url, params=param, opt=options)\n",
    "print('connection successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5281f829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cleaning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cleaning.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#cleaning data def\n",
    "def cleaning(all_data): \n",
    "    leie = all_data.drop_duplicates()\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    leie['price'] = leie['price'].str[:-3]\n",
    "    leie['price'] = leie['price'].str.replace('\\xa0', '')\n",
    "    recover = leie[~leie['price'].str.isdigit()]\n",
    "    if len(recover) > 0:\n",
    "        leie.loc[~leie['price'].str.isdigit(), ['price']] = recover['square_metre']\n",
    "        leie.loc[~leie['price'].str.isdigit(), ['r_type_amount']] = recover['price']\n",
    "        leie.loc[~leie['price'].str.isdigit(), ['square_metre']] = '0'\n",
    "        leie.loc[~leie['price'].str.isdigit(), ['price']] = leie['price'].str[:-3]\n",
    "        leie.loc[~leie['price'].str.isdigit(), ['price']] = leie['price'].str.replace('\\xa0', '')\n",
    "    leie.loc[0, 'link'] = leie.loc[0, 'trash2']\n",
    "\n",
    "    leie[['type', 'rooms_amount']] = leie['r_type_amount'].str.split(' ∙ ', expand=True)\n",
    "    del leie['r_type_amount']\n",
    "\n",
    "    leie = leie.reindex(('name', 'from', 'address', 'square_metre', 'price', 'type', 'rooms_amount', 'link'), axis=1)\n",
    "    leie['price'] = leie['price'].map(int)\n",
    "    leie['square_metre'] = leie['square_metre'].str.split().str[0]\n",
    "    leie['square_metre'] = leie['square_metre'].map(int)\n",
    "    leie.loc[leie['type'] == 'Garasje/Parker', ['type']] = 'Garasje/Parkering'\n",
    "\n",
    "    if len(leie.loc[leie['price'] < 100, 'price'])>0:\n",
    "        leie.loc[leie['price'] < 100, 'price'] =0\n",
    "        \n",
    "    return leie"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
