{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaabf82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from fake_useragent import UserAgent as UA\n",
    "import time\n",
    "import json\n",
    "from selenium.webdriver.common.by import By\n",
    "from seleniumwire import webdriver\n",
    "#from selenium.webdriver.support import expected_conditions as EC\n",
    "#from selenium.webdriver.support.ui import WebDriverWait\n",
    "#from selenium.webdriver import Keys\n",
    "\n",
    "#proxy changes\n",
    "\n",
    "options = {'proxy': {\n",
    "        'http': 'http://Qm5ZLm:tjaEeq@45.146.183.178:8000',\n",
    "        'https': 'http://Qm5ZLm:tjaEeq@45.146.183.178:8000'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47d7ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile proxies.py\n",
    "\n",
    "def proxies():\n",
    "    options = {'proxy': {\n",
    "        'http': 'http://Qm5ZLm:tjaEeq@45.146.183.178:8000',\n",
    "        'https': 'http://Qm5ZLm:tjaEeq@45.146.183.178:8000'}}\n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a4e49f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile connect_site.py\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from fake_useragent import UserAgent as UA\n",
    "\n",
    "#requests and bs4 connect\n",
    "def connect(url, params={}, opt={\"proxy\": {}}):\n",
    "    ua = UA()\n",
    "    header = {\n",
    "        'user-agent': ua.random,\n",
    "        'x-requested-with': 'XMLHttpRequest'}\n",
    "    proxies = opt['proxy']\n",
    "    resp = rq.get(url, headers=header, proxies=proxies, params=params, timeout=1)\n",
    "    resp.encoding = 'utf-8-sig'\n",
    "    soup = bs(resp.text, 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af57468a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting collect.py\n"
     ]
    }
   ],
   "source": [
    "#%%writefile collect.py\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "from fake_useragent import UserAgent as UA\n",
    "import time\n",
    "\n",
    "\n",
    "#collecting data\n",
    "def collect(categ, url, param, options):\n",
    "    \n",
    "    #requests and bs4 connect\n",
    "    def connect(url, params={}, opt={\"proxy\": {}}):\n",
    "        ua = UA()\n",
    "        header = {\n",
    "            'user-agent': ua.random,\n",
    "            'x-requested-with': 'XMLHttpRequest'}\n",
    "        proxies = opt['proxy']\n",
    "        resp = rq.get(url, headers=header, proxies=proxies, params=params, timeout=1)\n",
    "        resp.encoding = 'utf-8-sig'\n",
    "        soup = bs(resp.text, 'lxml')\n",
    "        return soup\n",
    "    \n",
    "    alt = []\n",
    "    counter = iter(range(1, 100))\n",
    "    param_switcher = 0\n",
    "    try:\n",
    "        while True:\n",
    "            soup = connect(url, params=param, opt=options)\n",
    "            print(f'connection successful - {next(counter)}')\n",
    "            for i in soup.find_all('article'):\n",
    "                one = []\n",
    "                one.append(i.find(\"a\").text) #name\n",
    "                one.append(i.find('span', {'class':'text-12 text-gray-500'}).text) #from\n",
    "                one.append(i.find('span', {'class':'text-14 text-gray-500'}).text) #adress\n",
    "                #trying to find square_metre, price\n",
    "                sqm_pr = i.find('div', {'class': 'mt-16 flex justify-between sm:mt-8 sm:block space-x-12 font-bold whitespace-nowrap'})\n",
    "                if not sqm_pr:\n",
    "                    sqm_pr = i.find('div', {'class': 'col-span-2 mt-16 flex justify-between sm:mt-4 sm:block space-x-12 font-bold whitespace-nowrap'})\n",
    "                if sqm_pr: #square_metre, price\n",
    "                    for spr in sqm_pr.find_all('span'): \n",
    "                        one.append(spr.text)\n",
    "                #trying to find price_desc, r_type_amount\n",
    "                desq_type = i.find('div', {'class': 'text-12 text-gray-500 flex flex-col mt-4 sm:block sm:mt-8'})\n",
    "                if not desq_type:\n",
    "                    desq_type = i.find('div', {'class': 'text-12 text-gray-500 flex flex-col mt-4 sm:block'})\n",
    "                if desq_type: #price_desc, r_type_amount\n",
    "                    for am in desq_type.find_all('span'):\n",
    "                        if am.text != ' âˆ™ ':\n",
    "                            one.append(am.text)\n",
    "                visning = i.find('span', {'class':'inline-block px-8 py-4 text-12 border border-bluegray-300 rounded-full'})\n",
    "                if visning:\n",
    "                    one.append(visning.text) #Visning\n",
    "                #link\n",
    "                one.append(i.find('a', {'class': 'sf-search-ad-link link link--dark hover:no-underline'})['href'])\n",
    "                #all\n",
    "                alt.append(one)\n",
    "            try:\n",
    "                link = soup.find('nav', {\"class\": 'pagination u-pb8 u-pt16'}).find_all('a')[-1]['href']\n",
    "                link = link[1:]\n",
    "                link = dict(map(lambda x: x.split('='), link.split('&')))\n",
    "                if param_switcher == 0:\n",
    "                    param = dict(map(lambda x: x.split('='), param.split('&')))\n",
    "                    param_switcher = 1\n",
    "                if link['page'] == param['page']:\n",
    "                    raise Exception('Last link.')\n",
    "                else:\n",
    "                    param = link.copy()\n",
    "                time.sleep(5)\n",
    "            except:\n",
    "                print('All data collected!')\n",
    "                break    \n",
    "    except Exception as e:\n",
    "        print(f\"Something wrong: {e}\")\n",
    "    print(f'All rows -- {len(alt)} --')\n",
    "    return alt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
