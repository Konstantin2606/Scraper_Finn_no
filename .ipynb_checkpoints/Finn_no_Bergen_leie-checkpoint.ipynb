{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaabf82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from fake_useragent import UserAgent as UA\n",
    "import time\n",
    "import json\n",
    "from selenium.webdriver.common.by import By\n",
    "from seleniumwire import webdriver\n",
    "#from selenium.webdriver.support import expected_conditions as EC\n",
    "#from selenium.webdriver.support.ui import WebDriverWait\n",
    "#from selenium.webdriver import Keys\n",
    "\n",
    "#proxy changes\n",
    "options = {'proxy': {\n",
    "        'http': 'http://Qm5ZLm:tjaEeq@45.146.183.178:8000',\n",
    "        'https': 'http://Qm5ZLm:tjaEeq@45.146.183.178:8000'}}\n",
    "\n",
    "#requests and bs4 connect\n",
    "def connect(url, params={}, opt={\"proxy\": {}}):\n",
    "    ua = UA()\n",
    "    header = {\n",
    "        'user-agent': ua.random,\n",
    "        'x-requested-with': 'XMLHttpRequest'}\n",
    "    proxies = opt['proxy']\n",
    "    resp = rq.get(url, headers=header, proxies=proxies, params=param, timeout=1)\n",
    "    resp.encoding = 'utf-8-sig'\n",
    "    soup = bs(resp.text, 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5281f829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect(url, param): #collecting data def\n",
    "    alt = []\n",
    "    try:\n",
    "        while True:\n",
    "            soup = connect(url, params=param, opt=options)\n",
    "            for i in soup.find_all('article'):\n",
    "                p = i.find_all('span')\n",
    "                one = []\n",
    "                one.append(i.find(\"a\").text)\n",
    "                for o in p:\n",
    "                    one.append(o.text)\n",
    "                one.append(i.find('a')['href'])\n",
    "                alt.append(one)\n",
    "            try:\n",
    "                link = soup.find('nav', {\"class\": 'pagination u-pb8 u-pt16'}).find_all('a')[-1]['href']\n",
    "                link = link[1:]\n",
    "                link = dict(map(lambda x: x.split('='), link.split('&')))\n",
    "                if link['page'] == param['page']:\n",
    "                    raise Exception('Last link.')\n",
    "                else:\n",
    "                    param = link\n",
    "                time.sleep(5)\n",
    "            except:\n",
    "                break\n",
    "    except:\n",
    "        print('Something wrong.')\n",
    "        \n",
    "    print('All is collected!')\n",
    "    return alt\n",
    "\n",
    "def data(alt): #make columns data def\n",
    "    leie = pd.DataFrame(alt)\n",
    "    leie.columns = ('name', 'from', 'trash', 'address', 'square_metre', 'price', 'r_type_amount', 'promoting', 'link', 'trash2')\n",
    "    return leie\n",
    "\n",
    "def cleaning(all_data): #cleaning data def\n",
    "    leie = data(all_data).drop_duplicates()\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    leie['price'] = leie['price'].str[:-3]\n",
    "    leie['price'] = leie['price'].str.replace('\\xa0', '')\n",
    "    recover = leie[~leie['price'].str.isdigit()]\n",
    "    if len(recover) > 0:\n",
    "        leie.loc[~leie['price'].str.isdigit(), ['price']] = recover['square_metre']\n",
    "        leie.loc[~leie['price'].str.isdigit(), ['r_type_amount']] = recover['price']\n",
    "        leie.loc[~leie['price'].str.isdigit(), ['square_metre']] = '0'\n",
    "        leie.loc[~leie['price'].str.isdigit(), ['price']] = leie['price'].str[:-3]\n",
    "        leie.loc[~leie['price'].str.isdigit(), ['price']] = leie['price'].str.replace('\\xa0', '')\n",
    "    leie.loc[0, 'link'] = leie.loc[0, 'trash2']\n",
    "\n",
    "    leie[['type', 'rooms_amount']] = leie['r_type_amount'].str.split(' ∙ ', expand=True)\n",
    "    del leie['r_type_amount']\n",
    "\n",
    "    leie = leie.reindex(('name', 'from', 'address', 'square_metre', 'price', 'type', 'rooms_amount', 'link'), axis=1)\n",
    "    leie['price'] = leie['price'].map(int)\n",
    "    leie['square_metre'] = leie['square_metre'].str.split().str[0]\n",
    "    leie['square_metre'] = leie['square_metre'].map(int)\n",
    "    leie.loc[leie['type'] == 'Garasje/Parker', ['type']] = 'Garasje/Parkering'\n",
    "\n",
    "    if len(leie.loc[leie['price'] < 100, 'price'])>0:\n",
    "        leie.loc[leie['price'] < 100, 'price'] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f32517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start():\n",
    "    with open('category_link.json', \"r\") as file:\n",
    "        data = json.load(file)\n",
    "        print('Сhoose a category:', *data.keys(), sep='\\n', end='\\n\\n')\n",
    "    while True:\n",
    "        try:\n",
    "            chose = input()\n",
    "            url = data[chose]\n",
    "            print(url)\n",
    "            break\n",
    "        except:\n",
    "            print('Something wrong, try again.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54561ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "aed3d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = 'https://www.finn.no/realestate/lettings/search.html'\n",
    "param= {\n",
    "    'geoLocationName': 'Bergen',\n",
    "    'lat': '60.39358',\n",
    "    'lon': '5.32479',\n",
    "    'radius': '20000',\n",
    "    'sort': 'PUBLISHED_DESC',\n",
    "    'page': '1'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "1554f95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All is collected!\n"
     ]
    }
   ],
   "source": [
    "all_data = collect(url, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce54a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f9c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "leie = cleaning(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc7de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to csv\n",
    "leie.to_csv('leie_120723.csv', sep=',', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aa5c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leie[(leie['type'] != 'Andre') & (leie['type'] != 'Garasje/Parkering')].sort_values(by='price').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "49072a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
